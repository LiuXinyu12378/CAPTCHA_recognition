                  epoch,         train/box_loss,         train/cls_loss,         train/dfl_loss,   metrics/precision(B),      metrics/recall(B),       metrics/mAP50(B),    metrics/mAP50-95(B),           val/box_loss,           val/cls_loss,           val/dfl_loss,                 lr/pg0,                 lr/pg1,                 lr/pg2
                      0,                0.99043,                 2.4812,                0.97785,                0.99697,                0.49558,                0.51628,                0.30293,                 1.0526,                 2.4825,                0.84228,             0.00031673,             0.00031673,             0.00031673
                      1,                0.75714,                0.76828,                0.85962,                0.99929,                    0.5,                0.57817,                0.47671,                0.85525,                 2.0032,                0.82607,             0.00058577,             0.00058577,             0.00058577
                      2,                0.74922,                0.65274,                0.84656,                0.99682,                0.54166,                0.99206,                0.79058,                 0.7472,                 1.3397,                0.81451,             0.00078879,             0.00078879,             0.00078879
                      3,                0.71367,                0.61472,                0.84804,                0.99735,                0.90318,                0.99456,                0.80821,                0.68764,                 1.1665,                0.80415,              0.0009258,              0.0009258,              0.0009258
                      4,                 0.6793,                0.55808,                0.84242,                0.99085,                      1,                  0.995,                0.83486,                0.68572,                 0.8614,                0.81063,              0.0009968,              0.0009968,              0.0009968
                      5,                0.65322,                0.52723,                0.83651,                 0.9961,                      1,                  0.995,                0.81781,                0.68123,                0.60527,                0.80673,             0.00084184,             0.00084184,             0.00084184
                      6,                0.65494,                0.50968,                0.83363,                0.99554,                      1,                  0.995,                0.84192,                0.57788,                0.52682,                0.79361,             0.00084184,             0.00084184,             0.00084184
                      7,                0.58281,                0.46577,                  0.825,                0.99753,                      1,                  0.995,                0.84002,                0.57842,                0.47102,                0.79407,              0.0006768,              0.0006768,              0.0006768
                      8,                0.59864,                 0.4545,                0.83001,                 0.9978,                      1,                  0.995,                0.84125,                 0.5926,                0.45379,                0.79596,             0.00051177,             0.00051177,             0.00051177
                      9,                0.59046,                0.43919,                0.82115,                0.99337,                0.99558,                0.99496,                0.84729,                0.57525,                0.43488,                0.79118,             0.00034674,             0.00034674,             0.00034674
